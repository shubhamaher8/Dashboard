# âš¡ AI Energy & COâ‚‚ Dashboard

Live app âœ https://ai-sustainable-co2-energy-dashboard.streamlit.app/

> Measure, visualize, and compare the environmental footprint of LLM inference across different models â€” in real time.

![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?logo=python&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸŒ Overview

This interactive Streamlit app estimates electricity usage and COâ‚‚ emissions produced when running prompts on different large language models via OpenRouter. It tracks token usage, estimates energy consumption, and visualizes the total and perâ€‘prompt environmental impact â€” helping you make greener AI choices.

### What you can do

- ğŸ§ª Run prompts against multiple AI models
- ğŸ”‹ Estimate energy use (kWh) per query
- ğŸŒ«ï¸ Convert energy to COâ‚‚ emissions (kg), using a US grid average factor
- ğŸ“ˆ Explore charts for trends, correlations, and model share
- ğŸ—‚ï¸ Review a query history with tokens, energy, and COâ‚‚ per run

---

## ğŸš€ Live Demo

Open the hosted app on Streamlit Cloud:

- App: https://ai-sustainable-co2-energy-dashboard.streamlit.app/


---

## ğŸ§  How it works

The app calls OpenRouterâ€™s chat completion API, reads token usage, and applies modelâ€‘specific energy factors to estimate electricity and emissions.

### ğŸ§® Footprint calculations

- Energy factor by model (kWh per 1K tokens)
- US grid average emission factor: 0.4 kg COâ‚‚ per kWh (configurable in code)

Formulas:

- $E_{kWh} = \dfrac{\text{tokens}}{1000} \times \text{energyFactor(model)}$
- $\text{COâ‚‚}_{kg} = E_{kWh} \times 0.4$

### ğŸ“¦ Model energy factors (defaults in code)

| Model | kWh / 1K tokens |
|---|---:|
| x-ai/grok-4-fast:free | 0.00045 |
| openai/gpt-oss-20b:free | 0.00040 |
| google/gemma-3n-e4b-it:free | 0.00015 |
| meta-llama/llama-4-maverick:free | 0.00035 |
| default (fallback) | 0.00030 |

> These are illustrative factors intended for relative comparison, not lifecycleâ€‘accurate measurements. See â€œNotes & caveats.â€

---

## ğŸ§· Key screens

- ğŸ“¨ Latest Prompt Analysis: response viewer with token/energy/COâ‚‚ metrics
- ğŸ§­ Dashboard KPIs: total energy, total COâ‚‚, prompts processed, avg tokens per prompt
- ğŸ“Š Statistical Analysis: average and median COâ‚‚ per prompt
- ğŸ“‰ Charts & Analytics:
	- COâ‚‚ share by model (pie)
	- Tokens over time (line)
	- Tokens vs COâ‚‚ correlation (scatter/line)
	- Input vs Output tokens for the latest prompt (bar)
- ğŸ“– Query History table

---

## ğŸ› ï¸ Local setup (Windows / PowerShell)

1) Clone or download this repository.

2) Create a virtual environment (optional but recommended):

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

3) Install dependencies:

```powershell
pip install -r requirements.txt
```

4) Run the app:

```powershell
streamlit run app.py
```

5) Open the Streamlit sidebar and paste your OpenRouter API key when prompted.

---

## ğŸ”‘ Configuration

OpenRouter API key is entered securely via the Streamlit sidebar at runtime.

---

## ğŸ“š Project structure

```
app.py              # Streamlit app
requirements.txt    # Python dependencies
Readme.md           
public/             # static assets
```

---

## ğŸ§­ Usage guide

1. Enter your OpenRouter API key in the sidebar.
2. Select a model from the dropdown.
3. Type your prompt and click â€œGenerate & Analyze.â€
4. Review the AI response, token usage, energy, and COâ‚‚ output.
5. Explore the analytics and history to compare models and prompts.

---

## ğŸ§© Tech stack

- ğŸ–¼ï¸ Streamlit for UI and state management
- ğŸ”— Requests for API calls
- ğŸ§® Pandas for data handling
- ğŸ“ˆ Plotly Express for interactive charts

---

## ğŸ—ºï¸ Roadmap

- âœ… Perâ€‘model energy factors and token accounting
- âœ… KPI dashboard with charts and history
- â³ Export to CSV / JSON
- â³ Model latency and cost overlays
- â³ Regionâ€‘specific grid emission factors
- â³ Persistent storage (e.g., SQLite) beyond the session

Contributions welcome â€” see below!


---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) included.
